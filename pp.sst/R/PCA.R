
# functions for the new PCA method: that is, PCA w.r.t. sample covariance matrix, downweighted by the Gneiting weight function

#' computes the weight matrix for downweighing the sample covariance matrix by distance.
#'
#' @param dt The data table.
#' @param phi Weight function, takes parameter \code{L}, i.e. phi = phi(d,L) where d is the distance of the grid points.
#' @param L Parameter for the weight function.
#'
#'
#' @export

weight_mat = function(dt, phi = GneitingWeightFct, L = 2500)
{
  # reduce to purely spatial data:

  dt = dt[year == min(year) & month == min(month),]

  dt = dt[!(is.na(Bias_Est) | is.na(Ens_bar) )]

  # find distance matrix
  sp <- sp::SpatialPoints(cbind(x=dt[, Lon],
                                y=dt[, Lat]),
                          proj4string = sp::CRS("+proj=longlat +datum=WGS84"))
  Dist <- sp::spDists(sp, longlat = TRUE)

  # get weights

  weights = phi(Dist, L)

  return(matrix(weights, nrow = dim(Dist)[1]))
}


#' computes and saves the SVD of the sample covariance matrices downweighted by distance of gridpoints
#'
#' @param dt The data table
#' @param weight_mat The matrix containing the weights for tapering: Has dimension n x n, where n is the number of grid_ids in water in dt.
#'                   Should be generated by the function weight_mat.
#' @param Y,M The years and months considered.
#' @param nPCs vector of same length as M containing the number of principal components to consider.
#' @param save_years For these years sam_cov generates and saves the sample covariance matrices,
#'                       using for each year all previous years.
#' @param save_dir The directory to save in.
#' @param file_name The saved files are named paste0(file_name,"_m",+,"_y",++,".RData"), where + is the month and ++ the year.
#'
#'
#' @export

PCA_cov = function(dt, weight_mat,
                       Y=unique(dt[,year]),
                       M = 1:12, nPCs,
                       save_years = 2013:2018, save_dir, file_name = "PCA_cov")
{
  dt = dt[year %in% Y & month %in% M,]

  dt = dt[!(is.na(Bias_Est) | is.na(Ens_bar) | is.na(SD_hat))]

  num_loc = dt[year == min(year) & month == min(month),.N]

  # get for each month the normalized data matrix, and conduct a PCA on the tapered covariance matrix

  for(m in M)
  {
      full_data_mat = matrix(dt[month == m,SST_bar - SST_hat],nrow = num_loc)

    for(y in save_years)
    {
      print(paste0("month = ",m,', year = ',y))

      num_years = max(which(Y < y))
      sam_cov_mat = 1/num_years * full_data_mat[,1:num_years] %*% t(full_data_mat[,1:num_years])

      Sigma = weight_mat * sam_cov_mat

      PCA = irlba::irlba(Sigma, nv = nPCs[which(M == m)])

      full_file_name = paste0(file_name,"_m",m,"_y",y,".RData")
      save(PCA, file = paste0(save_dir,full_file_name))
    }
  }
}



#' Forecasts by PCA
#'
#' @description Generates forecasts for the PCA post-processing approach.
#'
#' @param dt the data table.
#' @param Y,M Integer vectors containing year(s) and month(s).
#' @param n Integer. Size of the desired forecast ensemble.
#' @param nPCs Integer vector containing the numbers of considered principal components.
#' @param cov_dir,cov_file_name Where the PCA covariance matrices are stored and how they are named, see \code{sam_cov}.
#'
#' @return data table containing n columns with noise and n columns with forecasts.
#'
#' @examples \dontrun{}
#'
#' @author Claudio Heinrich
#'
#' @export

forecast_PCA_mult_corr = function(dt, Y, M,
                        n = 10, nPCs,
                        mc_cores = 1,
                        noise = FALSE,
                        cov_dir, cov_file_name = "PCA_cov")
{

  dt = dt[year %in% Y,][month %in% M,]

  dt_water = dt[!(is.na(Ens_bar) | is.na(SST_bar))]

  SD_cols = c("Lon","Lat","grid_id","month","year","YM",
              "SST_hat","SST_bar","Ens_bar","Bias_Est","var_bar","SD_hat")
  SD_cols = SD_cols[which(SD_cols %in% colnames(dt))]
  fc_water <- na.omit( dt_water[,.SD,.SDcols = SD_cols])

  # parallelize:
  forecast_by_month = function(m)
    {
      print( paste0("Month = ",m))

      dt_month = fc_water[month == m,]

      for(y in Y)
      {
        print(y)
        load(file = paste0(cov_dir,cov_file_name,"_m",m,"_y",y,".RData"))


        eigen_vectors <- PCA$u[,1:nPCs[m]]
        sqrt_sing_values <- sqrt(diag(x = PCA$d[1:nPCs[m]], nrow = length(PCA$d[1:nPCs[m]]))) # the awkward notation ensures that diag does the right thing if nPCs = 1.
        mar_sds <- sqrt(rowSums((eigen_vectors %*% sqrt_sing_values)^2))

        dt_ym = dt_month[year == y,]

        # do marginal correction
        var_correct_vec = dt_ym[,SD_hat] / mar_sds
        var_correct_mat = diag(var_correct_vec)

        # generate noise
        no = var_correct_mat %*% eigen_vectors  %*% sqrt_sing_values %*% matrix(rnorm(nPCs[m] * n),nrow = nPCs[m], ncol = n)

        for(i in 1:n)
        {
          dt_month[year == y, paste0("no",i):= no[,i]]
          dt_month[year == y, paste0("fc",i) := rowSums(.SD),
                   .SDcols = c("Ens_bar","Bias_Est",paste0("no",i))]
          dt_month[year == y, paste0("fc",i) := lapply(.SD,trc),.SDcols = paste0("fc",i)]
          if(! noise)
          {
            dt_month[, (paste0("no",i)):= NULL]
          }
        }

      }
    return(dt_month)
  }

  temp = parallel::mclapply(M,forecast_by_month,mc.cores = mc_cores)
  fc_water = rbindlist(temp)

  #-------- add land --------------

  fc_land = dt[is.na(Ens_bar) | is.na(SST_bar),.SD,.SDcols = SD_cols]
  fc_land[,  paste0("fc",1:n):= NA]

  if(noise)
  {
    fc_land[,  paste0("no",1:n):= NA]
  }

  fc = rbindlist(list(fc_water,fc_land), fill = TRUE)


  # order:

  fc = fc[ order(year,month,Lon,Lat)]

  return(fc)
}


#' Forecasts by PCA
#'
#' @description Generates forecasts for the PCA post-processing approach.
#'
#' @param dt the data table.
#' @param Y,M Integer vectors containing year(s) and month(s).
#' @param n Integer. Size of the desired forecast ensemble.
#' @param nPCs Integer vector containing the numbers of considered principal components.
#' @param cov_dir,cov_file_name Where the PCA covariance matrices are stored and how they are named, see \code{sam_cov}.
#'
#' @return data table containing n columns with noise and n columns with forecasts.
#'
#' @examples \dontrun{}
#'
#' @author Claudio Heinrich
#'
#' @export


forecast_PCA_add_corr = function(dt, Y, M,
                                 n = 10, nPCs,
                                 noise = FALSE,
                                 cov_dir, cov_file_name = "PCA_cov",
                                 mc_cores = 1)
{

  dt = dt[year %in% Y,][month %in% M,]

  dt_water = dt[!(is.na(Ens_bar) | is.na(SST_bar))]

  SD_cols = c("Lon","Lat","grid_id","month","year","YM",
              "SST_hat","SST_bar","Ens_bar","Bias_Est","var_bar","SD_hat")
  SD_cols = SD_cols[which(SD_cols %in% colnames(dt))]
  fc_water <- na.omit( dt_water[,.SD,.SDcols = SD_cols])

  # parallelize:
  forecast_by_month = function(m)
  {
    print( paste0("Month = ",m))

    dt_month = fc_water[month == m,]

    for(y in Y)
    {
      print(y)
      load(file = paste0(cov_dir,cov_file_name,"_m",m,"_y",y,".RData"))


      eigen_vectors <- PCA$u[,1:nPCs[m]]
      sqrt_sing_values <- sqrt(diag(x = PCA$d[1:nPCs[m]], nrow = length(PCA$d[1:nPCs[m]]))) # the awkward notation ensures that diag does the right thing if nPCs = 1.
      mar_sds <- sqrt(rowSums((eigen_vectors %*% sqrt_sing_values)^2))

      dt_ym = dt_month[year == y,]

      # do marginal correction
      var_correct_vec = pmax(dt_ym[,SD_hat^2] - mar_sds^2,0)

      # generate correlated noise
      no_1 = eigen_vectors  %*% sqrt_sing_values %*% matrix(rnorm(nPCs[m] * n),nrow = nPCs[m], ncol = n)
      # generate independent noise
      no_2 = rnorm(n = n*length(var_correct_vec),sd = rep(var_correct_vec,n))
      #sum
      no = no_1 + matrix(no_2,ncol = n)

      for(i in 1:n)
      {
        dt_month[year == y, paste0("no",i):= no[,i]]
        dt_month[year == y, paste0("fc",i) := rowSums(.SD),
                 .SDcols = c("Ens_bar","Bias_Est",paste0("no",i))]
        dt_month[year == y, paste0("fc",i) := lapply(.SD,trc),.SDcols = paste0("fc",i)]
        if(!noise)
        {
          dt_month[, paste0("no",i):= NULL]
        }
      }

    }

    return(dt_month)
  }

  temp = parallel::mclapply(M,forecast_by_month,mc.cores = mc_cores)
  fc_water = rbindlist(temp)

  #-------- add land --------------

  fc_land = dt[is.na(Ens_bar) | is.na(SST_bar),.SD,.SDcols = SD_cols]
  fc_land[,  paste0("fc",1:n):= NA]

  if(noise)
  {
    fc_land[,  paste0("no",1:n):= NA]
  }

  fc = rbindlist(list(fc_water,fc_land), fill = TRUE)


  # order:

  fc = fc[ order(year,month,Lon,Lat)]

  return(fc)
}



# get_PCs = function(dt = NULL,
#                    y,
#                    m,
#                    PCA_depth = 4,
#                    mar_var_correct = TRUE,
#                    saveorgo = FALSE,
#                    save_dir = "./Data/PostClim/SFE/Derived/PCA/",
#                    file_name = "PCs.RData",
#                    cov_dir = "~/PostClimDataNoBackup/SFE/PCACov/")
# {
#
#
#   if(is.null(dt))
#   {
#     print("load and prepare data")
#     dt = load_combined_wide(bias = TRUE)
#     trash = c(paste0("SST",1:10))
#     dt[, (trash):=NULL]
#     dt = dt[year %in% y & month %in% m,]
#   }
#
#   #find land grid ids:
#
#   land_grid_id <- dt[year %in% y & month %in% m & (is.na(Ens_bar) | is.na(SST_bar)),
#                      .(Lon,Lat,grid_id,month,year,YM)]
#   SD_cols = c("Lon","Lat","grid_id","month","year","YM",
#               "SST_hat","SST_bar",paste0("Ens",1:ens_size),"Ens_bar","Bias_Est","var_bar","SD_hat")
#
#   fc <- na.omit( dt[year %in% y & month %in% m ,.SD,.SDcols = SD_cols])
#
#
#   #get covariance matrices
#
#   print("data preparation complete - getting covariance matrices next:")
#
#   for(mon in m)
#   {
#     load(file = paste0(cov_dir,"CovRes_mon",mon,".RData"))
#
#     PCA = irlba::irlba(res_cov, nv = PCA_depth,fastpath = FALSE)
#
#     for(y_0 in y)
#     {
#       for (d in 1:PCA_depth)
#       {
#         fc[month == mon & year == y_0, paste0("PC",d) := PCA$d[d] * PCA$u[,d]]
#       }
#
#       if(mar_var_correct)
#       {
#         eigen_vectors <- PCA$u[,1:PCA_depth]
#         sing_values <- diag(x = PCA$d[1:PCA_depth], nrow = length(PCA$d[1:PCA_depth]))
#         mar_sds <- sqrt(rowSums(( eigen_vectors %*% sing_values)^2))
#
#         for(d in 1:PCA_depth)
#         {
#           fc[month == mon & year == y_0, paste0("PC_marcor_",d) := SD_hat * PCA$d[d] * PCA$u[,d] / mar_sds]
#         }
#       }
#     }
#   }
#
#
#   fc_land <- list()
#   fc_land[[1]] = fc
#   fc_land[[2]] = land_grid_id
#   fc_land = rbindlist(fc_land, fill = TRUE)
#   fc_land = fc_land[ order(year,month,grid_id)]
#   fc = fc_land
#
#   #-------- save -------
#
#   if(saveorgo)
#   {
#     save(fc, file = paste0(save_dir,file_name))
#   }
#
#   return(fc)
# }
